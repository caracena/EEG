% This is "sig-alternate.tex" V2.0 May 2012
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.5 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.5) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@hq.acm.org)
% ===============================================================
%
% For tracking purposes - this is V2.0 - May 2012

\documentclass{sig-alternate}
\usepackage{hyperref}
\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

%\title{Benchmarking for emotion recognition in DEAP dataset}
\title{Toward an Unified Analysis Framework for EEG-based Emotion Recognition}


\numberofauthors{8} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
\author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
\alignauthor
some people
}
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.


% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
some abstract
\end{abstract}

% A category with the (minimum) three required fields
%\category{H.4}{Information Systems Applications}{Miscellaneous}
%A category including the fourth, optional field follows...
%\category{D.2.8}{Software Engineering}{Metrics}[complexity measures, performance measures]

\keywords{some, keywords}

\section{Introduction}
Emotion is critical aspect of the human behavior, influencing vital activities 
such as communication and  learning. Despite its relevance...  
\section{Background}

\section{Empirical Study}
We performed an exploratory study to generate a baseline 


\subsection{Research Questions}
	
\subsection{Data}

For our research we used the famous dataset for the analysis of human affective states called
 Database for Emotion Analysis using Physiological Signals (DEAP)~\cite{deap2011}. This
 dataset contains electroencephalogram and peripheral physiological signals of 32 healthy
 participants (50\% female), aged between 19 and 37 (mean age 26.9), while they were watching
 40 one-minute long excepts of music videos. For each video, the dataset has a label for
 valence, arousal, dominance and liking levels according a process that mixed Last.fm application
 and subjective annotation of subjects. 

The web site of the dataset (\url{http://www.eecs.qmul.ac.uk/mmv/datasets/deap/}) allows
 you to download the raw data of the experiment (bdf files). These files are generated by the Active
 recording software of Biosemi and incorporate signals from 48 channels (32 EEG channels, 12 peripheral
 channels, 3 unused channels and 1 status channel) at a sample rate of 512Hz. The experiments were recorded
 in Twente in The Netherlands and in Geneva in Switzerland, and due to a different revision of the hardware,
 there are some minor differences in the format, mainly regarding to the order of the channels.
    
In addition, it is available a pre-processed dataset for Python and MATLAB platforms. This dataset contains
 files where the data signals is downsampled to 128Hz and the minor differences in the format between both
 experiment locations are resolved. Also, the next steps were applied:
\begin{enumerate}
\item A bandpass frecuency filter from 4.0 to 45.0 Hz was applied.
\item Electrooculogram (EOG) artifacts such as blinks and saccades were removed.
\item Data was averaged to the common reference.
\item The data was segmented into 60 second trials and a 3 second pre-trial baseline removed.
\item The trials were reordered from presentation order to video (Experiment\_id) order.
\end{enumerate} 

In this research, due to the convenient pre-processing carried out, we chose to use the pre-processed
 dataset. For each subject we had the next arrays:

\begin{table}[h!]
\footnotesize
\begin{center}
\begin{tabular}{|p{1cm}|p{2cm}|p{4.5cm}|}
      	\hline 
      	Array name & Array shape & Array content \\ 
      	\hline 
      	data & 40 x 40 x 8064 & video/trial x channel x signal \\ 
      	\hline
      	labels & 40 x 4 & video/trial x label (valence, arousal, dominance, liking) \\ 
      	\hline 
\end{tabular} 
\end{center}
\caption{Pre-processed dataset arrays}
\label{tab:dataset}
\end{table}       	
	
\subsection{Exploratory Data Analysis}

To get a sense of the dataset we started doing a exploratory data analysis of it. 	
	
\subsection{Takahashi method (2004)}	

In 2004, Kazuhiko Takahashi published his work called 
\textit{REMARKS ON EMOTION RECOGNITION FROM MULTI-MODAL BIO-POTENTIAL SIGNALS}~\cite{takahashi2004}. This 
research aimed to achieve a classification of 5 emotions (joy, anger, sadness, fear, and relax)
using multi-modal biopotential signals such as brain signals, pulse and skin conductance. He
 did experiments in order to collect data and then make a posterior analysis using algorithms
 like Support Vector Machine and Artificial Neural Networks. His results reached a precision of
 41.7\% for 5 emotions and 66.7\% for 3 emotions. 

This work is one of the first that tries to use machine learning algorithms
 over biological signals features for emotion recognition. In order to see
 how this field has been growing over last decade, this research is a good
 candidate to start the list of included works in the benchmark.  

\subsubsection{Experiment and Data}


\subsubsection{Feature Extraction}

To characterize the data this work used the next statistical features:
\begin{enumerate}
\item Mean ($\mu_{X}$)
\item Standard Deviation ($\sigma_{X}$)
\item Mean of absolute differences \\ \\ $\delta_{X} = \frac{1}{N-1} \sum^{N-1}_{n=1}|X(n+1)-X(n)|$
\item Mean of normalized absolute differences ($\overline{\delta_{X}} = \frac{\delta_{X}}{\sigma_{X}}$)
\item Mean of absolute second differences \\ \\ $\gamma_{X} = \frac{1}{N-2} \sum^{N-2}_{n=1}|X(n+2)-X(n)|$
\item Mean of normalized absolute second differences \\ ($\overline{\gamma_{X}} = \frac{\gamma_{X}}{\sigma_{X}}$)
\end{enumerate}  

\subsubsection{Emotion Recognition Method}
	

\subsection{Murugappan method (2010)}	

Murugappan et al. have quite an interesting story related to the emotion assessment through EEG analysis. Starting from 2008, several studies could be found in literature corresponding to this author, using different combinations of features, EEG channels and algorithms in order to classify discrete emotions such as disgust, happy, surprise, sad and anger.(CITAR los paper de muru).

For the present benchmark, we are centered in one of the mentioned Murugappan's works, where an experiment was conducted for collecting EEG data of 20 subjects, for the classification of five emotions, namely disgust, happy, surprise, fear and neutral. A wavelet-based approach was performed, three different features were proposed for the analysis and two classifiers were used, obtaining a maximimum average classification rate of 83.26\% with KNN and 75,21\% with LDA \cite{Murugappan2010Classification}.

Since Murugappan is an active actor in the emotion recognition field, turns to be important to include this study in benchmark and see how those proposed features behave with the DEAP dataset.




\subsection{Experimental Design Overview}
\subsubsection{Independent Variable}
\subsubsection{Dependent Variable }
\subsubsection{Controlled Factors}
\subsubsection{Threats to Validity}	

\section{Results and Analysis}

\subsection{Feature Impact Study}
\subsection{ }

\section{Discussion}

\section{Related Work}

\section{Conclusions}

\section{Acknowledgments}

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!
%
%APPENDICES are optional
%\balancecolumns


\end{document}
